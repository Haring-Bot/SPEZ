{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e794d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTImageProcessor\n",
    "from transformers import ViTForImageClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    ToTensor,\n",
    "    Resize,\n",
    ")\n",
    "\n",
    "setTypes = [\"train\", \"test\", \"validation\"]\n",
    "classes = [\"Chamo\", \"Hawassa\", \"Koka\", \"Lan\", \"Tana\", \"Ziway\"]\n",
    "\n",
    "def splitDataset(pTrain, pTest):\n",
    "    if pTrain+ pTest > 1:\n",
    "        print(\"pTrain and pTest in the splitData function are larger than 1. Please adjust. \\n !!Script terminated!!\")\n",
    "        return 0\n",
    "    elif pTrain + pTest > 0.9:\n",
    "        print(\"! Warning, the parameters of the splitData() function leave less then 10% of the dataset for validation use. Please use smalle values!\")\n",
    "    else:\n",
    "        print(\"starting to split the data\")\n",
    "    \n",
    "    pathAllImages = \"../data/images\"\n",
    "\n",
    "\n",
    "    allTestFolderFull = False\n",
    "    while allTestFolderFull == False:\n",
    "        allImages = os.listdir(pathAllImages)\n",
    "        amountImages = len(allImages)\n",
    "        amountTrainImages = math.floor(amountImages * pTrain)\n",
    "        amountTestImages = math.floor(amountImages * pTest)\n",
    "\n",
    "        print(\"spliting the dataset into: \\n\", amountTrainImages, \" amount of train images \\n\", amountTestImages, \"amount of test images\\n\", amountImages - amountTrainImages - amountTestImages, \"amount of validation images\")\n",
    "        trainImages = []\n",
    "        for elements in range (amountTrainImages):\n",
    "            randomChoice = random.choice(allImages)\n",
    "            trainImages.append(randomChoice)\n",
    "            allImages.remove(randomChoice)\n",
    "\n",
    "        testImages = []\n",
    "        for elements in range (amountTestImages):\n",
    "            randomChoice = random.choice(allImages)\n",
    "            testImages.append(randomChoice)\n",
    "            allImages.remove(randomChoice)\n",
    "\n",
    "        validationImages = allImages\n",
    "\n",
    "        if all(any(sub in s for s in testImages) for sub in classes):\n",
    "            if all(any(sub in s for s in validationImages) for sub in classes):\n",
    "                allTestFolderFull = True\n",
    "        else:\n",
    "            print(\"first try splitting the images left one folder empty. Trying to split again.\")\n",
    "\n",
    "    # print(len(trainImages))\n",
    "    # print(len(testImages))\n",
    "    # print(len(validationImages))\n",
    "\n",
    "    #copy images in folder\n",
    "    datasetF = \"../data/dataset\"\n",
    "    trainF = \"../data/dataset/train\"\n",
    "    testF = \"../data/dataset/test\"\n",
    "    validationF = \"../data/dataset/validation\"\n",
    "\n",
    "    if os.path.exists(datasetF):\n",
    "        shutil.rmtree(datasetF)\n",
    "\n",
    "\n",
    "    for setType in setTypes:\n",
    "        setTypeP = os.path.join(datasetF, setType)\n",
    "        os.makedirs(setTypeP)\n",
    "        for classType in classes:\n",
    "            os.makedirs(os.path.join(setTypeP, classType))\n",
    "\n",
    "    for image in os.listdir(pathAllImages):\n",
    "        for classType in classes:\n",
    "            if classType in image:\n",
    "                imageType = classType\n",
    "\n",
    "        if image in testImages:\n",
    "            shutil.copy(pathAllImages + \"/\" + image, testF + \"/\" + imageType)\n",
    "        if image in trainImages:\n",
    "            shutil.copy(pathAllImages + \"/\" + image, trainF + \"/\" +  imageType)\n",
    "        if image in validationImages:\n",
    "            shutil.copy(pathAllImages + \"/\" + image, validationF + \"/\" +  imageType)\n",
    "\n",
    "    return datasetF\n",
    "\n",
    "def train(datasetF, device):\n",
    "    modelName = \"google/vit-large-patch16-224\"\n",
    "    \n",
    "\n",
    "    dataset = load_dataset(\"imagefolder\", data_dir = datasetF)\n",
    "\n",
    "    processor = ViTImageProcessor.from_pretrained(modelName)\n",
    "    size = processor.size[\"height\"]\n",
    "    mean = processor.image_mean\n",
    "    std = processor.image_std\n",
    "    \n",
    "    trainTransforms = Compose([\n",
    "        RandomResizedCrop(size),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "    valTransforms = Compose([\n",
    "        Resize(size),\n",
    "        CenterCrop(size),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "    \n",
    "    def applyTrainTransforms(examples):\n",
    "        examples[\"pixel_values\"] = [trainTransforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "        return examples\n",
    "\n",
    "    def applyValTransforms(examples):\n",
    "        examples[\"pixel_values\"] = [valTransforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "        return examples    \n",
    "    \n",
    "    id2label = {id: label for id, label in enumerate(dataset[\"train\"].features[\"label\"].names)}\n",
    "    label2id = {label: id for id, label in id2label.items()}\n",
    "\n",
    "    dataset[\"train\"].set_transform(applyTrainTransforms)\n",
    "    dataset[\"test\"].set_transform(applyValTransforms)\n",
    "    dataset[\"validation\"].set_transform(applyValTransforms)\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        pixel_values = torch.stack([example[\"pixel_values\"] for example in batch])\n",
    "        labels = torch.tensor([example[\"label\"] for example in batch])\n",
    "        return{\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "    labels  = dataset['train'].features['label'].names\n",
    "    print(labels)\n",
    "\n",
    "\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        modelName, \n",
    "        num_labels = len(labels),\n",
    "        id2label=id2label, \n",
    "        label2id=label2id, \n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    train_args = TrainingArguments(\n",
    "        output_dir=\"output-models\",\n",
    "        per_device_train_batch_size=4,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        num_train_epochs=2,\n",
    "        fp16=False,\n",
    "        save_steps=10,\n",
    "        eval_steps=10,\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-4,\n",
    "        save_total_limit=2,\n",
    "        remove_unused_columns=False,\n",
    "        push_to_hub=False,\n",
    "        report_to='tensorboard',\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        train_args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"validation\"],\n",
    "        data_collator=collate_fn,\n",
    "        tokenizer=processor,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    outputs = trainer.predict(dataset[\"test\"])\n",
    "    print(outputs.metrics)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"starting to split the dataset\")\n",
    "    datasetFolder = splitDataset(0.8, 0.1)\n",
    "    print(\"starting to train the model\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"gpu found. Using cuda.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"No gpu found. Using cpu instead.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train(datasetFolder, device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
