%article
@article{DevilInDetail,
  author={Zheng, Heliang and Fu, Jianlong and Zha, Zheng-Jun and Luo, Jiebo},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Looking for the Devil in the Details: Learning Trilinear Attention Sampling Network for Fine-Grained Image Recognition}, 
  year={2019},
  volume={},
  number={},
  pages={5007-5016},
  keywords={Recognition: Detection;Categorization;Retrieval;Representation Learning},
  doi={10.1109/CVPR.2019.00515}}

@article{ImageIsWorth,
  author       = {Alexey Dosovitskiy and
                  Lucas Beyer and
                  Alexander Kolesnikov and
                  Dirk Weissenborn and
                  Xiaohua Zhai and
                  Thomas Unterthiner and
                  Mostafa Dehghani and
                  Matthias Minderer and
                  Georg Heigold and
                  Sylvain Gelly and
                  Jakob Uszkoreit and
                  Neil Houlsby},
  title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition
                  at Scale},
  journal      = {CoRR},
  volume       = {abs/2010.11929},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.11929},
  eprinttype    = {arXiv},
  eprint       = {2010.11929},
  timestamp    = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{AttentionIsAll,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention Is All You Need},
  journal      = {CoRR},
  volume       = {abs/1706.03762},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.03762},
  eprinttype    = {arXiv},
  eprint       = {1706.03762},
  timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ViTvsCNN,
  author       = {Maithra Raghu and
                  Thomas Unterthiner and
                  Simon Kornblith and
                  Chiyuan Zhang and
                  Alexey Dosovitskiy},
  title        = {Do Vision Transformers See Like Convolutional Neural Networks?},
  journal      = {CoRR},
  volume       = {abs/2108.08810},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.08810},
  eprinttype    = {arXiv},
  eprint       = {2108.08810},
  timestamp    = {Mon, 23 Aug 2021 14:07:13 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-08810.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Tilapia,
  title={Morphological variations of wild populations of Nile tilapia (Oreochromis niloticus) living in extreme environmental conditions in the Kenyan Rift-Valley},
  author={Ndiwa, Titus Chemandwa and Nyingi, Dorothy Wanja and Claude, Julien and Agnèse, Jean-François},
  journal={Environmental Biology of Fishes},
  volume={99},
  pages={473--485},
  year={2016},
  publisher={Springer},
  doi={10.1007/s10641-016-0492-y}
}

@article{OpportunitiesAndChallenges,
    author = {He, Y and Mulqueeney, J M and Watt, E C and Salili-James, A and Barber, N S and Camaiti, M and Hunt, E S E and Kippax-Chui, O and Knapp, A and Lanzetti, A and Rangel-de Lázaro, G and McMinn, J K and Minus, J and Mohan, A V and Roberts, L E and Adhami, D and Grisan, E and Gu, Q and Herridge, V and Poon, S T S and West, T and Goswami, A},
    title = {Opportunities and Challenges in Applying AI to Evolutionary Morphology},
    journal = {Integrative Organismal Biology},
    volume = {6},
    number = {1},
    pages = {obae036},
    year = {2024},
    month = {09},
    abstract = {Artificial intelligence (AI) is poised to revolutionize many aspects of science, including the study of evolutionary morphology. While classical AI methods such as principal component analysis and cluster analysis have been commonplace in the study of evolutionary morphology for decades, recent years have seen increasing application of deep learning to ecology and evolutionary biology. As digitized specimen databases become increasingly prevalent and openly available, AI is offering vast new potential to circumvent long-standing barriers to rapid, big data analysis of phenotypes. Here, we review the current state of AI methods available for the study of evolutionary morphology, which are most developed in the area of data acquisition and processing. We introduce the main available AI techniques, categorizing them into 3 stages based on their order of appearance: (1) machine learning, (2) deep learning, and (3) the most recent advancements in large-scale models and multimodal learning. Next, we present case studies of existing approaches using AI for evolutionary morphology, including image capture and segmentation, feature recognition, morphometrics, and phylogenetics. We then discuss the prospectus for near-term advances in specific areas of inquiry within this field, including the potential of new AI methods that have not yet been applied to the study of morphological evolution. In particular, we note key areas where AI remains underutilized and could be used to enhance studies of evolutionary morphology. This combination of current methods and potential developments has the capacity to transform the evolutionary analysis of the organismal phenotype into evolutionary phenomics, leading to an era of “big data” that aligns the study of phenotypes with genomics and other areas of bioinformatics.},
    issn = {2517-4843},
    doi = {10.1093/iob/obae036},
    url = {https://doi.org/10.1093/iob/obae036},
    eprint = {https://academic.oup.com/iob/article-pdf/6/1/obae036/60113405/obae036.pdf},
}

@article{autoencoders,
  title={A deep learning approach for morphological feature extraction based on variational auto-encoder: an application to mandible shape},
  author={Tsutsumi, Masato and Saito, Nen and Koyabu, Daisuke and Furusawa, Chikara},
  journal={NPJ Systems Biology and Applications},
  volume={9},
  number={1},
  pages={30},
  year={2023},
  doi={10.1038/s41540-023-00293-6}
}

@article{counterfactual,
  title={Explainable image classification with evidence counterfactual},
  author={Vermeire, Tom and Brughmans, Dieter and Goethals, Sofie and de Oliveira, Raphael Mazzine Barbossa and Martens, David},
  journal={Pattern Analysis and Applications},
  volume={25},
  number={2},
  pages={381--394},
  year={2022},
  publisher={Springer},
  doi={10.1007/s10044-021-01055-y}
}

@INPROCEEDINGS{cows,
  author={Duraiswami, Neil R. and Bhalerao, Shrikant and Watni, Abhishek and Aher, Chetan. N.},
  booktitle={2022 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC)}, 
  title={Cattle Breed Detection and Categorization Using Image Processing and Machine Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  keywords={Machine learning algorithms;Image recognition;Image color analysis;Shape;Support vector machine classification;Morphology;Machine learning;Image Processing;Image classification;Machine learning;Supervised learning;Support Vector Machine},
  doi={10.1109/ASSIC55218.2022.10088381}}

@article{mandibleShape,
  author    = {Masato Tsutsumi and Nen Saito and Daisuke Koyabu and Chikara Furusawa},
  title     = {A deep learning approach for morphological feature extraction based on variational auto-encoder: an application to mandible shape},
  journal   = {npj Systems Biology and Applications},
  year      = {2023},
  volume    = {9},
  number    = {1},
  pages     = {30},
  doi       = {10.1038/s41540-023-00293-6},
  url       = {https://www.nature.com/articles/s41540-023-00293-6}
}

@article{neurology,
  author    = {M. Aloraini and A. Khan and S. Aladhadh and S. Habib and M. F. Alsharekh and M. Islam},
  title     = {Vision transformers (ViT) and deep convolutional neural network (D-CNN)-based models for MRI brain primary tumors images multi-classification supported by explainable artificial intelligence (XAI)},
  journal   = {The Visual Computer},
  year      = {2024},
  doi       = {10.1007/s00371-024-03524-x},
  url       = {https://link.springer.com/article/10.1007/s00371-024-03524-x}
}

@article{SAHP,
      title={A Unified Approach to Interpreting Model Predictions}, 
      author={Scott Lundberg and Su-In Lee},
      year={2017},
      eprint={1705.07874},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1705.07874}, 
}

@article{LIME,
      title={"Why Should I Trust You?": Explaining the Predictions of Any Classifier}, 
      author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
      year={2016},
      eprint={1602.04938},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1602.04938}, 
}

@article{DinoV2,
      title={DINOv2: Learning Robust Visual Features without Supervision}, 
      author={Maxime Oquab and Timothée Darcet and Théo Moutakanni and Huy Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and Hervé Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
      year={2024},
      eprint={2304.07193},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.07193}, 
}

@article{ViTneedTransformer,
      title={Vision Transformers Need Registers}, 
      author={Timothée Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski},
      year={2024},
      eprint={2309.16588},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.16588}, 
}

@article{morphometrics,
  author    = {Mark Webster and H. David Sheets},
  title     = {A Practical Introduction to Landmark-Based Geometric Morphometrics},
  booktitle = {Quantitative Methods in Paleobiology},
  editor    = {John Alroy and Gene Hunt},
  pages     = {163--188},
  publisher = {The Paleontological Society},
  year      = {2010},
  address   = {Chicago, IL},
  doi       = {10.1017/s1089332600001868}
}

@article{carnivores,
title = {Combining machine learning algorithms and geometric morphometrics: A study of carnivore tooth marks},
journal = {Palaeogeography, Palaeoclimatology, Palaeoecology},
volume = {522},
pages = {28-39},
year = {2019},
issn = {0031-0182},
doi = {https://doi.org/10.1016/j.palaeo.2019.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0031018219300045},
author = {Lloyd A. Courtenay and José Yravedra and Rosa Huguet and Julia Aramendi and Miguel Ángel Maté-González and Diego González-Aguilera and Mari Carmen Arriaza},
keywords = {Artificial Intelligence, Bone Surface modifications, Statistics, Taphonomy},
abstract = {Since the 1980s an intense scientific debate has revolved around the hunting capacities of early hominin populations and the behavioral patterns of carnivores sharing the same ecosystem, and thus competing for the same resources. This debate, commonly known as the hunter-scavenger debate, fostered the emergence of a new research line into the Bone Surface Modifications (BSMs) produced by both taphonomic agents. Throughout the following 20 years, multiple studies concerning the action of carnivores have been developed, with a particular focus on the oldest archaeological sites in East Africa. Recent technological advances applied to taphonomy have provided new insight into carnivore BSMs. A newly developed part of this work relies on Geometric Morphometrics (GMM) studies aimed at discerning carnivore agency through the morphologic characterization of tooth scores and pits. GMM studies have produced promising results, however methodological limitations are still present. This paper presents the first combined application of Machine Learning (ML) algorithms and GMM to the analysis of carnivore tooth marks, generating classification rates of 100% between carnivore species in some cases.}
}